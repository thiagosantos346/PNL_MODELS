{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pnl_word_embedding_WORD2VEC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "182LjblqGnVBkXHB9nmELMuCrk5AOmAbW",
      "authorship_tag": "ABX9TyNvrlZ/pTIUnV4oP24hgXMN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thiagosantos346/PNL_MODELS/blob/master/pnl_word_embedding_WORD2VEC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR3c7Y8U5YOs",
        "colab_type": "text"
      },
      "source": [
        "# Processamento de Linguagem Natual\n",
        "> ## *Word Embeddies com Word2Vec*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gccs_QOR57RV",
        "colab_type": "text"
      },
      "source": [
        "## Um breve handons na ferramenta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hakam3Sa6CfU",
        "colab_type": "text"
      },
      "source": [
        "Podemos fazer uso de vetores depalavras já prontas e executar operações nesse vetor, logo abaixo vamos fazer o download desse vetor de palavras num formato txt, do [Repositório de Word Embeddings do NILC](http://nilc.icmc.usp.br/nilc/index.php/repositorio-de-word-embeddings-do-nilc), antes de fazer o Download descomente o códgo das celulas abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBRVlRVAblUZ",
        "colab_type": "code",
        "outputId": "1a0b9709-a402-4d24-8c1f-1a114f67f4a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#!wget http://143.107.183.175:22980/download.php?file=embeddings/word2vec/cbow_s300.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-15 20:02:01--  http://143.107.183.175:22980/download.php?file=embeddings/word2vec/cbow_s300.zip\n",
            "Connecting to 143.107.183.175:22980... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 929305948 (886M) [application/octet-stream]\n",
            "Saving to: ‘download.php?file=embeddings%2Fword2vec%2Fcbow_s300.zip’\n",
            "\n",
            "download.php?file=e 100%[===================>] 886.25M  11.2MB/s    in 80s     \n",
            "\n",
            "2020-04-15 20:03:21 (11.1 MB/s) - ‘download.php?file=embeddings%2Fword2vec%2Fcbow_s300.zip’ saved [929305948/929305948]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GwzbTI1b_NN",
        "colab_type": "code",
        "outputId": "85aeff03-2a14-48fb-e005-f79517fd57a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#!unzip '/content/drive/My Drive/Colab Notebooks/cbow_s300.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Colab Notebooks/cbow_s300.zip\n",
            "  inflating: cbow_s300.txt           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syfp9mlJecxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cbow_300 = '/content/drive/My Drive/Colab Notebooks/word2vec/cbow_s300.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9j15jVW6xA2",
        "colab_type": "text"
      },
      "source": [
        "Esse vetor contem 300 dimenções, onde cada uma das linhas dessa lista de vetores representa uma palavra, logo a baixo é possivel ver a sua extrutura."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9puB0JLWcsAC",
        "colab_type": "code",
        "outputId": "96d7804c-6980-4632-8397-e7b9e1e0ca32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "with open(cbow_300) as f:\n",
        "  for line in range(10):\n",
        "    print(next(f))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "929606 300\n",
            "\n",
            "</s> -0.001667 -0.000158 -0.000026 0.001300 -0.000796 0.001527 0.000046 0.000584 0.000449 -0.000100 0.000353 0.001251 0.001069 0.000506 0.000574 0.000838 -0.000930 -0.001220 0.000317 0.001315 -0.001120 0.001373 -0.000040 -0.001580 0.000421 -0.000667 -0.001556 -0.000746 0.001604 0.001157 -0.000027 0.000354 0.000358 -0.000527 -0.000573 -0.001512 -0.001557 -0.001637 0.001617 -0.001511 -0.001022 -0.001426 0.001086 -0.001033 0.000593 0.000724 0.000627 -0.000450 -0.001140 0.000333 0.000524 0.001541 0.000284 0.000617 -0.000807 -0.000088 -0.000364 0.001126 -0.001230 -0.001138 -0.001280 0.001330 0.001257 0.000576 0.000764 0.000684 0.001008 -0.000215 -0.000629 -0.001228 -0.001557 -0.000311 -0.000246 0.000045 0.001136 -0.000645 -0.000549 0.001099 0.000858 -0.000886 0.000553 0.000303 0.001433 0.000732 0.001321 -0.000894 -0.000700 -0.000661 -0.001484 -0.000950 -0.001556 -0.000809 0.000348 -0.000068 0.000724 -0.000569 -0.000161 -0.001628 -0.001437 -0.000259 -0.000296 -0.001571 0.000149 0.000847 0.000613 0.000802 0.001507 0.001015 0.000377 0.000255 -0.000458 -0.000777 -0.001561 0.001601 -0.001520 -0.001210 0.000106 0.000714 0.000392 0.001311 -0.001192 -0.000090 -0.001097 0.000424 -0.000954 -0.001272 -0.001178 0.000036 -0.000181 0.000331 -0.001453 -0.001488 -0.001033 -0.000377 0.000257 -0.001418 0.001109 0.000722 0.000936 -0.000113 0.001215 -0.000263 0.000652 0.001190 -0.000258 0.001391 0.001213 0.000783 -0.001202 0.000470 -0.000879 0.000688 -0.001163 -0.001105 0.001497 0.001304 -0.001322 -0.001501 0.001377 0.001439 0.000884 0.000484 0.001239 -0.001578 0.000981 -0.000318 -0.001180 -0.001375 -0.001491 0.001057 -0.001028 0.000893 0.001028 0.000772 0.001636 -0.000331 -0.000247 -0.001006 -0.000329 0.000837 0.000605 -0.000959 0.001410 0.000488 0.001167 -0.000293 -0.001188 -0.000001 0.001135 0.001141 0.001504 0.000198 -0.001060 0.001551 -0.000003 -0.001474 -0.000391 -0.000880 0.000433 -0.000976 -0.001417 0.000563 -0.001188 0.000593 0.001584 -0.001602 -0.000439 -0.001148 -0.001256 0.001185 -0.000738 0.001543 -0.000846 -0.001029 -0.000641 -0.001587 0.001439 -0.001251 0.000942 -0.001414 -0.001106 0.001087 -0.000027 0.000757 -0.000159 -0.001014 -0.000891 0.000024 -0.000238 0.000157 -0.001067 0.000902 -0.001050 -0.000428 -0.001606 -0.000988 0.001391 0.001165 -0.000113 -0.001000 -0.000055 -0.001369 0.000684 0.000715 0.001407 0.000613 0.001389 0.001315 -0.000130 -0.001044 0.000175 -0.000035 0.000959 -0.000345 0.001209 -0.001251 -0.001219 0.001231 -0.000996 -0.001388 0.001038 0.001336 -0.001066 -0.000881 -0.001066 -0.001466 -0.000274 0.000201 0.000401 0.000132 0.000588 0.000589 -0.000128 0.001073 0.001197 0.000109 0.000770 0.001221 0.000996 -0.001174 0.000135 -0.001134 -0.001385 -0.000311 -0.001631 -0.000564 0.001162 -0.000322 -0.000469 0.001312 -0.001402 0.000239 0.000184 0.001300 0.000021 -0.001065 0.000047 -0.000301 0.001336 0.000332\n",
            "\n",
            ", -0.061483 -0.094368 -0.008557 -0.034702 0.021108 -0.011873 -0.041133 -0.095925 0.034668 -0.085286 0.076174 0.003314 0.019222 -0.038695 -0.008963 0.053399 0.162935 0.050372 -0.020163 -0.027230 0.061531 0.060840 0.074610 -0.056173 0.007621 -0.055220 0.018008 0.026096 0.033154 -0.082612 -0.081761 0.164978 -0.034423 0.003094 -0.018217 -0.087445 -0.074446 -0.000142 0.004218 0.036585 0.016095 -0.129141 -0.119698 -0.053717 0.005053 -0.114520 -0.017219 0.023693 -0.024115 0.053125 0.024658 -0.037689 0.012078 0.112701 0.028037 0.047618 -0.024196 0.050112 -0.073095 -0.090859 -0.030613 -0.109599 0.037756 0.063827 0.022537 -0.029640 -0.016311 0.021875 0.064882 0.039002 -0.082970 -0.043166 0.013695 -0.043153 -0.082203 -0.020087 -0.100360 0.007033 -0.074208 -0.067789 -0.024897 -0.020358 0.041731 0.101332 0.020217 -0.032473 0.087827 -0.033611 -0.150526 -0.016615 0.021147 -0.025058 0.097833 0.065067 0.051287 -0.079191 0.089563 -0.008436 -0.038352 0.019787 -0.058452 -0.009696 -0.051077 -0.112245 0.024886 -0.015172 -0.129670 0.068672 0.068483 0.009049 0.007055 -0.032763 0.001527 0.054264 0.029924 -0.023482 0.047470 0.008044 0.014534 0.071155 0.016700 -0.027491 -0.155782 0.039370 0.116605 -0.001262 -0.026638 -0.067078 0.078015 -0.066153 -0.039303 0.009535 -0.055698 -0.022250 0.046948 0.053810 0.038096 0.032157 -0.075257 0.008125 -0.034598 -0.020667 -0.003153 0.032491 -0.031064 0.030744 -0.049023 -0.046149 0.000792 0.010385 -0.057119 -0.122554 0.003210 -0.054363 -0.100899 0.069873 -0.009758 0.055455 0.049243 0.008346 -0.016087 0.093572 0.024125 0.058736 0.037243 -0.007478 0.032175 -0.054205 0.008798 0.032326 0.028384 -0.032259 -0.041842 -0.058281 -0.025145 0.011097 0.023598 -0.033376 0.026204 0.032505 -0.009283 0.041076 0.055565 -0.081757 -0.010077 0.058251 -0.014379 -0.040951 0.006938 -0.004179 0.052006 -0.063725 0.035674 -0.066554 0.030910 -0.004032 0.077445 0.029495 -0.064931 0.040263 -0.055423 -0.021571 0.086767 -0.003583 0.073308 -0.043991 0.022503 -0.028692 -0.063626 -0.048238 0.013439 -0.043673 -0.101352 -0.004321 0.125507 0.088486 0.042756 -0.014497 -0.053445 0.021800 0.038406 -0.034023 -0.074428 -0.132825 0.082152 -0.068497 0.004738 0.047527 -0.073890 0.051089 -0.055886 -0.047786 0.040247 -0.053966 -0.015752 0.099451 0.008218 -0.010716 -0.031540 0.036168 0.054244 0.051809 0.035158 0.043006 -0.027902 0.000130 0.103397 -0.114831 -0.036648 -0.036143 0.024432 0.084740 0.001801 0.044475 -0.035746 -0.024109 0.051210 -0.025769 0.016073 -0.000351 -0.029183 -0.075292 0.042163 0.025010 -0.041439 -0.059192 0.026617 -0.040852 0.034697 0.014691 -0.057382 0.046141 0.070360 0.045274 0.065880 0.011023 -0.031292 -0.015784 -0.023421 -0.042788 0.019669 0.035010 0.036188 -0.058060 -0.093562 0.030321 -0.054753 0.097162 0.001134 0.018939 -0.150218 -0.009928 0.051118 0.105212 -0.055051 -0.047959 -0.136800 -0.003198 0.068969 -0.022456\n",
            "\n",
            "de -0.232068 0.066729 0.103946 -0.072608 0.126237 -0.004782 -0.025139 -0.141489 -0.069438 -0.071078 0.175772 -0.017257 0.094824 0.011020 0.029226 -0.010670 0.144973 0.105333 -0.088273 -0.070952 0.054747 -0.048955 -0.047809 -0.030763 -0.052293 -0.003596 0.078465 0.144430 0.129697 -0.078427 -0.025080 0.212887 0.119806 0.101703 -0.142488 -0.031272 -0.026594 -0.109429 -0.154688 -0.121492 -0.103781 -0.177948 -0.125544 -0.120136 0.031658 0.054160 0.060493 -0.115676 0.132511 -0.001668 -0.125569 -0.124120 0.029025 0.006200 -0.007915 0.058489 0.122710 0.004660 -0.082200 0.123740 0.052747 -0.065657 0.154747 0.155071 0.003547 -0.154675 -0.035110 0.119117 0.080579 0.044262 0.048753 0.054975 -0.064624 -0.046866 0.028242 0.144197 0.029916 -0.024569 0.195781 -0.028608 -0.008233 -0.032542 0.012042 0.011934 -0.068173 0.037028 0.018363 -0.038244 -0.091176 -0.019795 0.051640 -0.008025 -0.025825 -0.001686 -0.069845 -0.039987 0.066244 0.088229 -0.171358 -0.030783 0.082344 0.059267 0.000550 -0.216285 -0.201356 -0.131063 -0.033069 -0.057126 -0.127576 -0.099251 -0.044669 0.035363 -0.119503 -0.090019 -0.006226 -0.000546 0.020731 0.016140 -0.007438 0.032885 -0.161048 0.105681 -0.115705 -0.078013 0.102293 -0.107958 -0.025926 -0.067986 0.017502 -0.054865 -0.007930 -0.006999 -0.000949 -0.026097 0.106295 0.115368 -0.033742 -0.046025 0.009641 -0.065890 0.198822 0.078333 0.062547 0.044947 -0.098424 0.140951 0.109045 -0.004204 -0.174950 0.034234 0.040793 -0.210289 0.104861 0.083616 -0.042511 -0.031439 -0.113108 0.000401 -0.171665 0.097890 0.008065 0.080684 -0.009576 -0.042125 0.177337 -0.005585 -0.004165 0.069755 -0.100323 -0.023289 0.039458 -0.089292 0.069543 -0.009576 0.011562 -0.076654 0.009681 -0.018808 -0.047881 0.026709 -0.021200 -0.032544 0.100362 0.037157 0.005169 -0.001280 -0.064330 -0.049024 -0.002354 0.004443 0.049129 0.026813 0.034249 0.068827 -0.038583 -0.116914 -0.107378 0.046983 0.038218 -0.082186 -0.124208 0.066872 -0.081745 -0.016516 0.016110 0.046844 0.176223 0.083604 -0.086893 -0.114739 -0.159588 0.007700 0.004887 0.006024 -0.020026 0.045816 0.033604 0.054474 0.089348 -0.024353 0.104835 0.084334 0.052662 -0.041422 -0.027877 0.002816 0.150068 -0.052310 0.017154 -0.152326 0.067753 -0.082644 0.119430 -0.012345 0.082965 -0.005791 -0.082770 -0.030068 -0.037331 -0.075347 0.035060 -0.092023 -0.001051 0.012675 0.128757 -0.048579 -0.078527 -0.134126 -0.060009 0.096834 -0.045947 0.132404 -0.030576 -0.006618 -0.088179 -0.124597 -0.095311 -0.086943 0.007010 0.059925 -0.077005 -0.035458 -0.017957 0.081104 0.060141 0.152996 0.083737 -0.025909 0.005420 -0.006300 -0.075839 -0.012399 -0.001624 0.039090 -0.040755 -0.013051 -0.072733 -0.048062 -0.082573 -0.013851 -0.120222 0.011452 -0.083538 0.015996 -0.110800 0.012405 0.045823 0.026705 -0.040789 0.064309 0.007381 -0.037854 0.076050 0.104702 0.010307 -0.103478 0.085227 0.064233 -0.015908 -0.047998\n",
            "\n",
            ". 0.027867 0.077901 -0.054738 -0.095938 -0.010536 0.015269 -0.005752 -0.048440 -0.104021 0.054583 0.050108 0.054979 0.071112 -0.056665 -0.140868 0.203626 0.211330 0.137270 -0.038069 -0.108607 0.060027 0.052436 0.126758 -0.078212 0.008864 -0.028087 0.029884 0.114899 -0.058657 -0.166441 -0.188866 0.294844 -0.147703 -0.095883 -0.104021 -0.097608 -0.172317 0.035795 -0.019025 0.057503 -0.030564 -0.125182 -0.257359 -0.106566 -0.002708 -0.035769 -0.072053 -0.005640 0.016920 0.155101 -0.226088 -0.070904 -0.110280 -0.075773 -0.190123 0.197397 -0.108603 0.155954 0.096544 -0.183301 0.008154 -0.195997 0.035284 -0.025561 0.159142 -0.141005 0.140643 -0.160588 0.140709 0.059974 -0.012396 -0.074953 -0.038325 -0.165941 -0.226005 -0.043738 0.052905 0.085072 -0.165731 0.016894 -0.136569 0.088165 -0.032044 0.022789 0.051207 0.015907 0.093662 0.037576 -0.286139 -0.107587 0.165001 0.095293 0.181427 0.038072 0.078180 -0.116599 0.138464 0.138386 0.020201 -0.028087 0.038829 -0.040074 -0.044944 -0.179895 0.035044 0.090347 -0.036088 0.154828 0.090421 0.172175 -0.127294 0.060227 0.164694 0.141367 0.049326 -0.136940 0.060633 -0.089581 -0.069639 0.043680 0.141455 -0.060588 -0.118859 0.181506 -0.051302 0.165763 0.151366 -0.191232 -0.103888 -0.077344 -0.016534 0.073607 -0.008464 0.216368 0.038251 0.002552 -0.112613 -0.049596 0.018040 -0.032907 -0.131335 -0.049530 0.057485 0.129446 -0.017884 0.075667 -0.061577 -0.015305 0.007649 0.116636 -0.132568 -0.244250 -0.048748 0.003139 -0.123311 0.018462 0.126955 0.079116 -0.067653 0.019126 0.044182 0.037610 0.199809 -0.118487 0.011276 -0.061652 -0.034426 -0.120148 -0.171490 0.009182 0.182921 -0.165212 0.149898 0.062080 -0.129040 0.051808 -0.075070 -0.068688 0.018707 -0.008050 0.108429 -0.111089 0.021230 -0.125982 0.077740 0.140251 -0.051900 0.036107 0.019580 -0.084050 0.065747 0.015718 -0.016900 -0.026964 0.126565 -0.087491 0.069504 0.108362 -0.006355 0.118521 -0.002510 0.060457 0.082848 0.000294 -0.037938 -0.026097 0.084446 0.015568 -0.050540 -0.117080 0.100227 -0.046050 -0.059615 0.086632 0.097266 0.084578 -0.036891 -0.033246 0.021302 -0.149581 -0.006353 -0.035713 -0.177163 -0.016629 -0.028634 -0.147015 -0.017861 0.009931 -0.181849 0.065564 -0.007616 0.094861 0.089787 0.005743 -0.127185 0.093027 -0.107247 -0.019161 -0.201082 -0.008504 0.126500 0.034318 0.011876 0.012696 -0.090981 0.012814 0.038388 -0.274763 -0.123303 -0.073078 0.027702 0.035841 -0.080954 0.091305 0.029009 -0.006000 0.121087 0.016678 -0.070181 -0.080839 -0.016332 -0.081390 -0.059594 0.131390 0.039603 -0.222503 -0.039382 -0.071041 0.267399 -0.010011 -0.077326 -0.044107 0.052901 0.023623 -0.087243 0.011539 -0.006381 -0.074194 -0.041591 -0.061872 -0.098552 -0.094357 -0.062879 -0.150341 -0.087596 0.330078 0.028435 0.087784 0.034434 -0.008122 -0.258485 -0.109828 0.013279 0.043340 0.136803 -0.081573 -0.136733 -0.081884 0.306241 0.093106\n",
            "\n",
            "a -0.019764 -0.096043 -0.010960 0.102012 -0.101848 -0.010257 0.004692 -0.165735 -0.179723 0.067659 0.037108 0.100931 -0.211779 0.163603 -0.042376 -0.021683 -0.014900 0.101581 -0.053583 0.065435 0.126251 0.062320 -0.057445 -0.107130 -0.037044 -0.072958 -0.066655 -0.067962 -0.070879 -0.187941 0.065208 0.102302 -0.024876 0.151433 0.012228 -0.065570 -0.063793 0.015519 0.046230 0.174824 -0.100376 -0.081244 -0.039337 0.017851 0.125168 -0.096404 -0.133070 -0.023451 0.117965 0.005949 0.038928 0.060488 -0.014678 0.024891 -0.001455 0.048539 0.133535 0.084564 0.018362 -0.054294 -0.235691 -0.151528 0.043101 -0.097685 -0.034775 -0.127507 0.010346 -0.010458 0.047631 0.002045 -0.013826 -0.139644 0.128220 -0.020997 -0.057176 0.007458 -0.033133 -0.083235 -0.075585 -0.079414 -0.023531 0.076794 0.051968 0.026857 0.007574 -0.039602 0.027458 -0.146083 0.008662 0.113647 0.007963 0.023413 0.088046 -0.079530 0.027995 -0.017113 -0.056750 0.069447 0.094213 0.123728 0.010051 -0.054795 0.041003 -0.044294 -0.066911 -0.025221 0.059618 0.023494 -0.095354 0.029266 0.047979 0.079102 -0.061757 0.116363 0.011112 0.136784 -0.027020 -0.002793 -0.092629 -0.047217 0.111263 0.102819 0.090932 -0.085343 -0.026490 -0.033315 -0.028970 -0.118673 -0.067360 -0.207183 -0.076011 0.017469 -0.078908 0.031023 0.090820 -0.054443 0.062466 0.065952 -0.028265 0.051329 0.090671 0.106923 0.028011 0.014720 -0.036025 0.099207 -0.013510 -0.147551 -0.077657 -0.099269 0.001171 0.059405 -0.006946 0.123997 0.023131 0.102308 -0.040784 0.027455 -0.181898 0.095958 0.155467 -0.077250 -0.124941 0.058529 0.035851 -0.004447 0.035127 -0.024015 -0.029101 -0.107558 0.055650 -0.017027 0.008997 -0.016504 0.018768 -0.080671 0.029003 0.013937 0.002876 -0.064262 0.001246 0.073494 -0.013986 -0.100303 0.027376 0.030375 -0.177618 0.016413 -0.008711 -0.257308 -0.031904 0.068326 0.038748 0.006762 -0.045245 0.038158 0.093055 -0.069432 -0.140442 -0.030486 -0.097529 0.251017 -0.059000 -0.037363 -0.020030 0.116937 0.018191 -0.005464 0.016485 0.009930 0.007318 -0.131821 -0.005316 -0.063905 0.066936 -0.007235 0.066709 0.153262 -0.087015 -0.196866 0.042973 0.124447 0.034619 -0.021113 0.029881 -0.072679 0.068707 -0.033823 -0.140311 -0.158137 0.215081 -0.020170 -0.062018 -0.038955 0.158768 -0.155656 0.016471 -0.071324 0.069629 -0.070692 0.114725 0.114054 0.154133 -0.143244 -0.082015 -0.070578 0.094558 -0.073491 -0.084676 0.089027 -0.053428 0.034783 0.007488 0.008849 0.137206 -0.061942 -0.155206 -0.022297 -0.054165 0.206418 0.058566 0.033847 0.039555 0.042072 -0.003160 0.350700 -0.067416 -0.089351 0.147734 0.026404 -0.128322 -0.143885 -0.189820 0.162824 -0.038651 -0.045660 0.083507 0.118510 -0.054740 -0.053446 -0.106545 -0.087144 -0.159905 0.006153 0.057539 0.079486 -0.015659 -0.014220 -0.013549 -0.122177 -0.154875 0.319072 -0.251233 0.070468 -0.084041 -0.067580 -0.163386 -0.026553 -0.033245 -0.035199\n",
            "\n",
            "o 0.050016 0.094213 -0.234393 0.057870 -0.255710 -0.099076 0.162541 -0.073166 -0.072231 0.087253 0.154162 -0.021438 0.095246 0.086680 0.027481 0.055959 0.176635 -0.158901 -0.076106 -0.036695 0.115689 -0.039255 -0.116532 -0.143528 0.059030 0.049429 -0.009721 0.204578 -0.020946 -0.254149 -0.167956 0.024087 -0.094412 -0.066287 -0.085987 -0.081115 -0.035314 -0.000736 0.069831 -0.034319 -0.041741 0.007945 0.106777 0.119971 -0.051358 0.152951 -0.109669 0.102599 0.102598 0.044424 -0.088313 0.142374 0.042868 -0.042467 0.199348 -0.234265 -0.044845 -0.109492 0.005783 -0.045873 -0.049017 -0.037446 0.105329 -0.163747 -0.139140 0.153179 -0.117726 -0.113436 0.010813 0.097110 0.074618 0.041083 0.082912 -0.052041 0.009895 0.160828 0.058190 -0.215907 -0.024543 0.042466 -0.011712 0.064930 0.097498 -0.080108 0.019837 -0.059179 0.077248 -0.135312 0.132748 0.069083 0.075949 -0.232743 0.078279 -0.078944 0.116486 0.004099 0.057786 -0.125938 0.068976 0.176170 0.044454 0.085901 0.033849 0.057793 -0.083662 0.061258 -0.037814 0.050392 -0.067302 -0.102103 -0.011153 0.029286 0.032976 0.003400 0.061664 0.076337 -0.097293 0.026432 -0.059397 -0.160978 0.069399 0.307550 0.069981 -0.122410 0.003086 0.027841 0.134213 -0.018279 -0.025608 -0.156602 0.062460 -0.051757 0.030337 -0.042270 0.007516 0.055478 0.075345 0.112685 -0.047181 0.001009 0.031433 -0.134699 -0.034702 -0.082685 -0.182748 -0.097813 0.053774 -0.067876 -0.090774 -0.035145 0.080364 -0.242563 0.024905 -0.012293 0.110051 0.103592 0.138403 -0.035121 0.037955 -0.028042 0.005687 0.042462 0.045434 0.127590 -0.049950 0.079609 -0.152268 -0.102837 -0.083840 -0.132681 -0.073176 0.031672 0.104991 0.082840 0.142188 -0.047643 0.054661 -0.112325 0.006551 0.079335 0.011705 -0.042121 0.086597 0.088994 0.079949 -0.002677 0.106816 -0.055035 0.068153 -0.167192 0.009149 -0.028594 -0.039560 0.001607 -0.122615 0.106024 0.107250 0.050540 -0.043291 0.061397 0.001380 0.054964 0.040893 -0.045046 0.002312 0.032035 -0.026698 -0.042064 0.144622 0.076241 0.024255 -0.086833 0.098275 -0.083894 0.086363 -0.004560 -0.029056 0.126784 0.071785 -0.025692 0.000966 0.100620 0.030299 -0.163968 0.042070 -0.198341 0.099603 -0.113758 0.124685 -0.069966 -0.165131 -0.134782 -0.020419 -0.112747 0.123515 -0.045274 0.167949 -0.109681 -0.146224 0.075453 0.054352 0.023153 -0.062161 -0.059457 -0.124327 0.041855 0.205124 -0.083616 -0.062827 0.017066 0.025000 0.079311 0.018874 -0.055492 -0.129246 0.099183 -0.022749 -0.079510 -0.130005 0.012160 0.060842 0.018816 -0.180103 0.057191 0.018971 0.216519 -0.003726 0.155861 0.112271 0.091379 -0.073707 -0.059254 0.011068 -0.005690 -0.098677 -0.082454 0.105838 0.042144 0.100894 0.096960 -0.228625 0.064737 0.022971 -0.001549 -0.105277 0.149519 -0.055187 0.201671 0.098550 0.056229 -0.107189 -0.005223 -0.077126 0.020865 -0.098107 0.064205 -0.174567 0.196321 0.233813 0.038634\n",
            "\n",
            "e -0.168088 -0.001531 0.017038 -0.137315 -0.026399 -0.018215 0.026076 0.019779 -0.095212 -0.090352 -0.106060 0.061975 -0.000318 -0.002945 0.119734 0.149804 0.108117 0.064784 0.065574 -0.038343 0.159915 -0.006124 -0.038307 -0.094810 -0.019356 -0.045115 -0.121859 0.028930 0.045017 -0.138268 0.099283 0.128659 0.077656 0.032982 -0.086139 0.051552 -0.077685 -0.066857 -0.045233 -0.185625 0.013728 -0.067088 -0.061796 0.091931 0.007931 -0.033784 -0.026604 0.026487 0.002281 0.000939 -0.043053 -0.082718 -0.101476 0.014253 0.106507 0.059285 -0.034097 0.032848 -0.067852 0.103892 0.020742 -0.049702 0.085734 0.069140 -0.036293 -0.001048 -0.043403 -0.033758 -0.041652 -0.049051 -0.070893 -0.002921 0.096254 -0.046406 -0.016074 0.074894 0.098854 -0.015867 -0.024065 0.048818 -0.058226 -0.031364 0.055631 -0.001012 0.002966 0.017624 0.082472 -0.025849 -0.099736 -0.065253 0.002511 0.026550 -0.046750 0.005665 0.058496 -0.068569 0.110588 -0.003354 -0.133236 -0.140404 0.090284 -0.089065 0.010600 -0.143848 0.023044 0.035726 0.044885 -0.081761 0.020406 0.045142 -0.099682 0.013478 -0.102208 -0.048206 0.040736 0.012733 0.064284 0.052800 0.046179 -0.083605 -0.002064 0.003024 0.078588 -0.075731 -0.038192 -0.010662 -0.062210 -0.060302 0.005740 -0.119290 0.049789 -0.009878 0.033791 0.145393 -0.064118 0.005292 -0.046015 -0.012572 -0.002266 0.018877 -0.114718 0.043831 0.036031 -0.077071 0.079499 0.047130 0.136516 -0.029402 -0.095073 -0.198367 0.077792 -0.092858 -0.115212 0.064883 -0.083748 -0.115535 -0.017903 0.080732 0.088457 0.037072 0.044588 0.042071 0.064027 0.035189 0.071027 -0.028330 0.026847 -0.005846 -0.003655 -0.019447 0.057641 -0.057623 0.032575 -0.009248 0.103035 -0.087592 0.049022 -0.030181 0.055313 0.001550 0.136222 -0.081518 -0.003322 -0.196934 -0.125240 -0.039119 0.082201 -0.036932 -0.030666 0.101376 -0.008224 0.045433 0.055995 -0.108370 0.120019 0.024427 -0.055956 0.076503 -0.063588 -0.091926 -0.047620 0.071838 -0.050062 0.122101 0.011679 0.015549 0.060463 -0.174818 0.006131 -0.035602 -0.039755 0.044683 -0.002324 -0.096353 0.153145 -0.181759 0.059133 0.008242 0.009471 0.004472 -0.005789 0.035746 0.107733 0.019606 0.035323 0.013101 0.078772 0.031495 0.011914 0.035316 0.029965 0.010626 0.024444 -0.036373 0.041982 -0.059195 -0.062521 -0.032445 -0.050086 -0.002740 -0.033702 -0.052157 -0.100889 0.010753 -0.017195 0.076872 -0.114096 -0.134334 0.019812 -0.147168 -0.048026 0.055315 -0.021564 0.092953 -0.070098 -0.009133 -0.021408 -0.043442 -0.059603 -0.026196 -0.046402 -0.024446 0.036482 -0.021195 -0.014285 -0.003113 -0.053620 -0.057722 -0.005912 -0.228597 -0.022520 0.008453 -0.131441 0.074053 0.010990 -0.029988 -0.106588 -0.005512 0.036736 -0.002115 -0.078824 -0.067073 0.034071 -0.037642 0.019106 0.080103 0.068267 -0.052487 -0.070635 0.073949 -0.056421 0.017687 0.011800 -0.014045 0.006226 -0.014210 0.088889 -0.007613 -0.042151 0.091935\n",
            "\n",
            "que 0.105677 -0.012054 -0.134709 -0.013888 -0.080373 -0.084105 0.028820 -0.039461 -0.011410 0.033408 -0.031719 0.198935 0.047353 -0.090613 -0.098891 -0.010202 0.144315 0.151674 0.016502 -0.133896 0.031100 -0.007432 -0.059600 0.059022 -0.038658 0.167877 0.082268 0.217249 -0.072088 0.076910 0.079216 -0.037108 0.014821 -0.078732 -0.035230 0.024507 -0.126809 -0.017172 0.040998 -0.043692 -0.149663 -0.049520 0.024513 -0.063125 0.058306 -0.012108 -0.119330 0.034781 -0.102405 0.088640 -0.272843 -0.059915 -0.108119 -0.004685 0.184494 0.029357 -0.012836 0.087409 -0.093633 0.141491 -0.051050 -0.072004 -0.164353 -0.078488 -0.075351 -0.029836 -0.011346 -0.081588 0.032113 -0.120232 -0.028536 0.010188 0.169394 -0.077409 -0.026955 0.083380 0.010644 0.026978 0.131446 -0.055521 -0.142428 -0.164762 0.016372 -0.254786 -0.015511 -0.044090 -0.091434 0.042059 -0.182369 -0.057621 -0.113482 -0.031757 0.036860 0.035760 -0.084302 -0.244284 0.014317 -0.110019 0.076959 -0.003242 0.058425 -0.068168 -0.150191 -0.054872 0.067636 -0.130009 0.033544 -0.028672 -0.029417 -0.003639 0.008028 0.067533 0.015459 0.057868 -0.095344 0.023596 0.005216 -0.068982 0.110498 -0.045724 0.067068 -0.103614 -0.010749 0.079515 -0.160577 -0.037640 -0.090058 0.194754 -0.137685 0.048330 0.023402 -0.080694 -0.076719 0.081176 0.145217 -0.312484 -0.158713 0.003970 0.017241 0.020559 0.019566 -0.020686 0.027909 -0.088033 0.055311 0.114986 0.046477 -0.026289 -0.085503 0.072325 0.033167 -0.027302 0.043202 -0.125175 -0.046430 -0.089749 -0.052517 -0.026923 -0.157140 0.142859 -0.035472 0.053636 -0.015367 -0.041692 0.004743 -0.053162 -0.073490 -0.031711 0.009967 -0.034655 0.209237 -0.052801 0.121190 -0.048079 0.203458 0.037113 -0.095015 0.143972 0.046959 -0.014909 0.169301 -0.034984 0.006088 -0.180444 -0.098740 -0.082224 0.042493 -0.048264 0.034078 -0.155237 0.049812 0.108571 -0.103458 0.015055 -0.005921 -0.020380 -0.059664 0.063496 0.120677 0.028720 0.010933 -0.034094 -0.033195 0.065065 -0.150067 -0.127015 -0.115948 -0.168308 -0.079605 0.112220 -0.024935 0.008233 -0.050985 -0.047235 -0.041944 0.099358 -0.094031 0.008722 -0.044243 0.091927 0.029639 0.053425 -0.020329 -0.007264 0.029055 -0.027748 0.021123 0.023926 -0.068259 -0.034626 0.010976 -0.027882 0.074465 0.017960 -0.142224 0.010472 -0.005171 0.001003 0.031482 0.048073 0.122005 -0.012546 -0.127375 0.137744 -0.043389 -0.067031 -0.028339 -0.102349 -0.001278 -0.075125 -0.209901 0.022713 0.123317 -0.005108 0.206613 -0.119748 0.148568 0.189863 -0.005551 0.042991 0.024824 0.095960 0.049202 -0.115647 -0.075263 -0.101255 0.047671 0.006936 -0.147872 -0.048649 0.152138 0.090100 -0.054797 0.180955 -0.016752 -0.090723 -0.126502 0.137744 0.065590 -0.095213 -0.141592 -0.081258 0.061414 0.138765 -0.047507 0.155577 -0.004058 -0.054305 -0.064755 -0.155780 0.019290 0.092772 -0.113740 0.062508 -0.108115 -0.104516 0.233178 0.085033 -0.063993 0.107476\n",
            "\n",
            "do -0.180377 0.215497 -0.243985 -0.111583 -0.213779 -0.101028 -0.000539 -0.101256 -0.070914 0.038753 0.046168 -0.014838 0.180611 0.000883 0.060867 0.085324 0.226791 -0.021134 -0.137997 -0.202197 0.148571 -0.050565 -0.078147 -0.128638 -0.060884 0.050100 0.018876 0.214215 0.115665 -0.095654 -0.142162 0.120025 -0.097131 0.072397 -0.038019 0.105100 0.071983 -0.160280 -0.051489 -0.098811 -0.117858 -0.034939 -0.009614 0.107021 -0.047199 -0.005264 -0.000139 0.071706 0.161239 -0.161907 -0.337947 0.006058 0.022506 -0.037415 0.171261 -0.062566 -0.062829 -0.086872 0.049601 0.208633 -0.010851 0.096788 0.242130 -0.103836 -0.078473 -0.008937 -0.192728 0.135349 -0.090459 0.275743 0.134895 0.051969 -0.132400 0.040473 -0.095963 0.027610 0.029590 -0.188700 0.164033 0.032661 -0.109406 0.180492 0.147311 0.025806 -0.079043 -0.050046 0.065651 -0.066955 0.037583 -0.031008 0.012122 -0.225802 0.106807 0.067123 0.035571 -0.204494 -0.004813 -0.022719 -0.267100 0.241056 0.115854 0.094971 -0.032575 0.045279 0.030343 -0.103868 0.013372 0.008258 0.027818 -0.051606 0.060680 0.094947 -0.025672 -0.044170 -0.007713 -0.008499 -0.111320 0.112186 -0.091970 -0.085167 0.001894 0.156088 -0.067075 -0.027825 0.093561 0.070251 0.049796 -0.161722 -0.051384 -0.124694 -0.016951 -0.141747 0.002894 -0.133038 -0.015664 0.080839 -0.090980 0.084050 0.089413 0.021215 0.043560 -0.075679 -0.068300 -0.025250 -0.157061 0.022866 0.055717 -0.019705 0.036159 0.183264 0.073571 -0.227341 -0.020978 0.064482 0.075304 0.010691 -0.068159 0.110613 0.047416 -0.029155 -0.043249 -0.074944 0.011065 -0.047526 0.018594 0.114240 -0.265600 0.007173 -0.118795 -0.109128 0.000016 -0.025266 -0.101829 0.167882 0.163892 -0.112688 -0.195755 -0.162868 0.114179 0.149630 0.075342 0.024940 0.099575 0.154626 0.069327 0.046685 0.046306 -0.138379 0.070196 -0.071198 0.028745 0.052231 -0.034552 -0.065006 0.070413 -0.061854 0.102099 0.063467 -0.002194 0.041076 -0.095035 0.138216 0.123084 -0.022177 0.178009 0.171209 0.193143 -0.170747 0.013212 0.020312 -0.129422 0.079598 -0.068529 -0.147807 0.047131 -0.137531 0.091482 0.030125 0.145402 -0.080191 0.025542 0.178609 0.118927 -0.206678 0.094064 -0.042739 -0.084631 -0.076197 0.253984 -0.273463 -0.026424 0.022400 0.012012 0.061563 0.131845 0.000155 -0.068048 -0.138741 -0.137770 0.143289 -0.017924 -0.111125 -0.055598 -0.012842 0.040329 0.034049 0.148260 -0.121714 -0.091318 0.030290 0.127014 0.037068 -0.070445 -0.136299 -0.232076 -0.028718 0.111683 -0.116630 -0.077730 0.033543 -0.032343 0.091454 0.094135 0.163275 0.123356 0.155053 0.137251 0.054886 0.086155 0.132626 -0.112011 0.103465 -0.085405 -0.075092 0.038307 0.075783 0.028715 0.020250 0.078956 0.012173 -0.058316 0.084967 -0.099896 -0.090466 -0.126150 0.144591 0.025099 0.059846 0.102206 0.092871 -0.004201 -0.062104 0.143311 -0.046741 0.010705 -0.065122 -0.074470 0.072302 0.144289 0.067299\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vO14QYx7IRt",
        "colab_type": "text"
      },
      "source": [
        "Ussando a biblioteca ``gensim.models`` e possivel importar esse modelo atravez da classe ``KeyedVectors``, pois trata-se de um dicionário do tipo: \n",
        "``{ key : vector }``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO1s17s8eMsL",
        "colab_type": "code",
        "outputId": "f69402ba-3c57-4f1c-cc01-552fcf9be4b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format(cbow_300)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNc2eobM7vFb",
        "colab_type": "text"
      },
      "source": [
        "É possível fazer operações matemáticas sobre esse vetores usando palavras por causa desse mapemento chave e vetor, veja um exemplo logo abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YliPCN2IfxJ6",
        "colab_type": "code",
        "outputId": "f76c12df-7baa-4390-bd89-a78e3a8dedd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model.most_similar(positive=[\"brasil\", \"argentina\", \"brasileiro\"], negative=[\"brasil\"])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('chileno', 0.5851722955703735),\n",
              " ('argentino', 0.5785882472991943),\n",
              " ('venezuela', 0.5730587840080261),\n",
              " ('bolívia', 0.5562254190444946),\n",
              " ('venezuelano', 0.5496551990509033),\n",
              " ('paraguaio', 0.5476757287979126),\n",
              " ('colômbia', 0.5461257696151733),\n",
              " ('uruguaio', 0.5247834920883179),\n",
              " ('mexicano', 0.5194203853607178),\n",
              " ('boliviano', 0.5097063183784485)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MrXR0td8A0r",
        "colab_type": "text"
      },
      "source": [
        "## Projeto de Exemplo :\n",
        "> Classificador para um Portal de noticias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ4VpBtC8QNt",
        "colab_type": "text"
      },
      "source": [
        "### Importação das bibliotecas e definição das constantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPK8_4spOTIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzCqak5DS_CL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFPOg2T1RVrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_PATH = '/content/drive/My Drive/Colab Notebooks/word2vec/teste.csv'\n",
        "TEST_PATH = '/content/drive/My Drive/Colab Notebooks/word2vec/treino.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iudQNCRRn3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_frame = pd.read_csv(TEST_PATH)\n",
        "train_data_frame = pd.read_csv(TRAIN_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "381_m_Z5IEEe",
        "colab_type": "text"
      },
      "source": [
        "## Tokenização das palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7_sZojPIOG-",
        "colab_type": "code",
        "outputId": "e9ce43b3-4d9c-4b39-ec7c-7f63110eae7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E7cIHhHIomM",
        "colab_type": "text"
      },
      "source": [
        " > `word_tokinizer`\n",
        "\n",
        " > `In`  : String\n",
        "\n",
        " > `Out` : String List\n",
        "\n",
        " > `Transformation` : Remove pontuation of String, and split string by withespace.\n",
        "\n",
        " > `Dependencies` : `string`,  `nltk` and download from nltk of `punkt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JELUX3vBIbVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_tokinizer(str_value):\n",
        "  string_list = list()\n",
        "  for tokenized in nltk.word_tokenize(str_value):\n",
        "    if tokenized not in string.punctuation:\n",
        "      string_list.append(tokenized.lower())\n",
        "  return string_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HY3YuClLZzF",
        "colab_type": "text"
      },
      "source": [
        "*Vamos testar a função* :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRkM8fNzLYtm",
        "colab_type": "code",
        "outputId": "1afd4bc0-4749-4ee9-994d-0fc63e0d78d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_tokinizer(\"Isso é apenas, um teste!\")"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['isso', 'é', 'apenas', 'um', 'teste']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddlk_T8SLyHA",
        "colab_type": "text"
      },
      "source": [
        "### Vetorização das palavras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AnMaJzMwwi-_"
      },
      "source": [
        " > `to_vector`\n",
        "\n",
        " > `In`  : \n",
        " \n",
        " >  `vector_model` : A KeyedVectors of word2vec format cbow.\n",
        "\n",
        " >  `vector_size` :   Length of vector cbow.\n",
        "\n",
        " >  `token_list` : A string list tokenized without ponctuation.\n",
        "\n",
        " > `Out` : Keyed Vector cbow.\n",
        "\n",
        " > `Transformation` :  Create a cbow vector with gived tokens.\n",
        "\n",
        " > `Dependencies` : `numpy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTgPH9AQLx0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def to_vector(vector_model, vector_size, token_list):\n",
        "  new_vector = np.zeros(vector_size)\n",
        "  for token in token_list:\n",
        "    try:\n",
        "      new_vector += vector_model.get_vector(token)\n",
        "    except KeyError:\n",
        "      if token.isnumeric():\n",
        "        new_vector += vector_model.get_vector('0'*len(token))\n",
        "      else: \n",
        "        new_vector += vector_model.get_vector('unknow')\n",
        "  return new_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n98MrG1hztfz",
        "colab_type": "text"
      },
      "source": [
        "Vamos testar a nossa função"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ2wLoVczxRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_vectorizer = word_tokinizer(\"Isso é apenas, um teste!\")\n",
        "vectorized = to_vector(model, 300, to_vectorizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbXc4RsN0LJr",
        "colab_type": "code",
        "outputId": "a8c95ef7-95ae-491f-e437-68e2f08775ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "print(vectorized)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.76383899 -0.051183   -0.25437501  0.190738   -0.74190397 -0.105513\n",
            "  0.40476399 -0.106963   -0.62952398  0.104172    0.04        0.31765001\n",
            "  0.277751    0.22644099 -0.063325    0.16420301 -0.158509   -0.650038\n",
            "  0.19140499 -0.317947   -0.099397    0.358317   -0.451312   -0.221784\n",
            "  0.14953599  0.255564   -0.07118299  0.101755    0.14946501 -0.36596799\n",
            " -0.158807   -0.30664699  0.040619    0.018848    0.009379   -0.01359801\n",
            "  0.61321401 -0.266844    0.10296802  0.194428   -0.20044001  0.45626301\n",
            "  0.469552    0.051236   -0.21709301  0.20070001  0.45306099 -0.02779601\n",
            "  0.177635    0.477815    0.221195   -0.21998201  0.363287    0.02257999\n",
            "  0.218468   -0.02604399  0.396597   -0.02958699 -0.11208001  0.24939599\n",
            " -0.301804   -0.046752    0.43709701 -0.01752601 -0.168916    0.308391\n",
            "  0.46415999 -0.33299099  0.084501   -0.29157998 -0.29948699 -0.190875\n",
            "  0.26654201 -0.04682     0.19820399 -0.149827   -0.153221   -0.53421301\n",
            " -0.17124899 -0.21134299 -0.238612   -0.086003    0.15542201 -0.100046\n",
            "  0.108919    0.323544    0.21163998 -0.39507801 -0.013454   -0.20589799\n",
            "  0.137547   -0.54651499 -0.232191    0.28447001 -0.42531601  0.150145\n",
            "  0.114818    0.052799    0.86991197  0.56933102  0.070345    0.037079\n",
            "  0.39099401 -0.252118    0.19509401  0.020547   -0.106281    0.461681\n",
            " -0.060376    0.24880401 -0.23114901 -0.39035501  0.33600299  0.581266\n",
            "  0.265317   -0.05104199  0.033483   -0.460944    0.359874   -0.43936799\n",
            " -0.180011   -0.35991701 -0.28872699 -0.05648899  0.333716    0.04028599\n",
            "  0.206434   -0.138515    0.11585202 -0.010278   -0.00240399 -0.096139\n",
            "  0.292836    0.14169    -0.007435   -0.37153701  0.55534101  0.214224\n",
            "  0.212103   -0.30377    -0.001563   -0.214821   -0.240299    0.08609901\n",
            " -0.06166199 -0.120526   -0.30741999  0.401871    0.26082401  0.105654\n",
            "  0.37458399  0.16724302 -0.428911   -0.35981    -0.10362301  0.12977701\n",
            " -0.01529299  0.23576699  0.315236   -0.10563099  0.126993    0.67678001\n",
            " -0.178268   -0.053055   -0.090226   -0.096377    0.360718    0.32648501\n",
            " -0.237796    0.038965    0.39349101 -0.082448   -0.10594699 -0.24327501\n",
            "  0.026184   -0.11745101  0.171486    0.03757401 -0.38851701  0.30947699\n",
            "  0.090116    0.178868   -0.37536499  0.55768001 -0.34084    -0.19634398\n",
            "  0.260637   -0.40924502 -0.021771   -0.001122   -0.083646    0.13386699\n",
            " -0.16401499  0.344005    0.01258802  0.185491    0.26429299  0.142722\n",
            " -0.63504302 -0.17045201 -0.213849   -0.155466   -0.099391    0.29579\n",
            "  0.14536999  0.134437    0.10472899 -0.18325599 -0.075283    0.33847599\n",
            "  0.234705   -0.052092   -0.07245701  0.25049699 -0.36083399  0.06981801\n",
            " -0.017814   -0.12093299 -0.537799   -0.29030001  0.13847601  0.31870101\n",
            " -0.014325    0.319793    0.314851   -0.34315099 -0.362476    0.402492\n",
            " -0.014166   -0.26280401  0.437196   -0.28947301  0.17178699 -0.003037\n",
            " -0.33801402 -0.35385101  0.081701    0.82684799  0.101042    0.04278201\n",
            "  0.443271    0.028843    0.41565199 -0.22421599 -0.013004   -0.282739\n",
            "  0.46194501 -0.320563   -0.016039   -0.278081   -0.09122     0.083257\n",
            "  0.316654   -0.32993299 -0.003345    0.18777601  0.06595301  0.542489\n",
            "  0.240493   -0.28405599  0.29568499 -0.116019    0.295481   -0.00324101\n",
            " -0.60009299  0.330282   -0.165456    0.164637   -0.13031301  0.118332\n",
            "  0.21941301  0.238542    0.22505199  0.53984     0.134834    0.017965\n",
            "  0.57082899 -0.16273899  0.35164298  0.32007298 -0.12646799  0.43057601\n",
            " -0.224285   -0.01057699  0.06814999  0.294051    0.098321   -0.05491999\n",
            " -0.43936999  0.16841     0.247505   -0.327337   -0.00717299  0.006647\n",
            "  0.254157    0.287247    0.186682    0.41383699 -0.36030299 -0.113217  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bGtWCBH2eRM",
        "colab_type": "text"
      },
      "source": [
        "Já temos um vetorizador de uma dimenção e um tokezinador, juntando os dois podemos montar nossa propria matriz esparçar de um conjunto de dados próprios e um vetor modelo `cbow` pronto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aJ_buHCh3D6g"
      },
      "source": [
        " > `to_vector`\n",
        "\n",
        " > `In`  : \n",
        " \n",
        " >  `vector_model` : A KeyedVectors of word2vec format cbow.\n",
        "\n",
        " >  `vector_size` :   Length of vector cbow.\n",
        "\n",
        " >  `token_list` : A string list tokenized without ponctuation.\n",
        "\n",
        " > `Out` : Keyed Vector cbow.\n",
        "\n",
        " > `Transformation` :  Create a cbow vector with gived tokens.\n",
        "\n",
        " > `Dependencies` : `numpy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gd6YEJm28bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_vector_matrix(vector_model, vector_size, fTokenizer, fVectorizer, string_list):\n",
        "  columns = len(string_list)\n",
        "  lines = vector_size\n",
        "  cbow_matrix = np.zeros((columns, lines))\n",
        "\n",
        "  for i in range(columns):\n",
        "    tokens_list = fTokenizer(string_list.iloc[i])\n",
        "    cbow_matrix[i] = fVectorizer(vector_model, vector_size, tokens_list)\n",
        "\n",
        "  return cbow_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTUmz7LNBQ8m",
        "colab_type": "text"
      },
      "source": [
        "### Treino do Modelo - CBOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgwwpPMU4239",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cbow_matrix_test = create_vector_matrix( model, 300, word_tokinizer,  to_vector, test_data_frame.title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW1h6idL62um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cbow_matrix_train = create_vector_matrix( model, 300, word_tokinizer,  to_vector, train_data_frame.title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8Mk8jKX67DE",
        "colab_type": "code",
        "outputId": "e1dcf516-a2e5-4b4d-e963-4462429e9948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(cbow_matrix_test.shape)\n",
        "print(cbow_matrix_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90000, 300)\n",
            "(20513, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wThoThpV7hni",
        "colab_type": "code",
        "outputId": "7deb96e1-9b18-4510-d1c7-f16b8327c097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter=400)\n",
        "\n",
        "lr.fit(cbow_matrix_train, train_data_frame.category)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=400,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJlSpL4cBXf1",
        "colab_type": "text"
      },
      "source": [
        "### Avaliação do modelo - CBOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7l9DLzd8RXi",
        "colab_type": "code",
        "outputId": "407372be-6600-4766-fcc8-9a480f31935b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr.score(cbow_matrix_test, test_data_frame.category)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7004444444444444"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqOnwSm29NFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "label_predict = lr.predict(cbow_matrix_test)\n",
        "cr = classification_report( test_data_frame.category, label_predict) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ41FB0o-v9Z",
        "colab_type": "code",
        "outputId": "c8701016-d845-4495-d205-922e4ef7e2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(cr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     colunas       0.50      0.78      0.61     15000\n",
            "   cotidiano       0.82      0.68      0.74     15000\n",
            "     esporte       0.79      0.89      0.84     15000\n",
            "   ilustrada       0.93      0.25      0.39     15000\n",
            "     mercado       0.66      0.83      0.73     15000\n",
            "       mundo       0.81      0.77      0.79     15000\n",
            "\n",
            "    accuracy                           0.70     90000\n",
            "   macro avg       0.75      0.70      0.68     90000\n",
            "weighted avg       0.75      0.70      0.68     90000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4rnY70s_mMD",
        "colab_type": "code",
        "outputId": "a2801e90-b009-4f11-d1d2-ac8c8758fdb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dc = DummyClassifier()\n",
        "dc.fit(cbow_matrix_train, train_data_frame.category)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DummyClassifier(constant=None, random_state=None, strategy='warn')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPOBIRwd_-bs",
        "colab_type": "code",
        "outputId": "ab1bfe35-3eca-4e2e-ece3-e984af52b299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dc.score(cbow_matrix_test, test_data_frame.category)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1651"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgMm3OTHAGpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_predict = dc.predict(cbow_matrix_test)\n",
        "cr = classification_report( test_data_frame.category, label_predict) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3zCpRTsAMl4",
        "colab_type": "code",
        "outputId": "9e8638b0-8f3c-47e8-c6bf-b0ed90a4c1af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(cr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     colunas       0.17      0.30      0.22     15000\n",
            "   cotidiano       0.16      0.08      0.11     15000\n",
            "     esporte       0.16      0.22      0.19     15000\n",
            "   ilustrada       0.17      0.01      0.01     15000\n",
            "     mercado       0.17      0.29      0.21     15000\n",
            "       mundo       0.16      0.10      0.12     15000\n",
            "\n",
            "    accuracy                           0.17     90000\n",
            "   macro avg       0.17      0.17      0.14     90000\n",
            "weighted avg       0.17      0.17      0.14     90000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhlpnjUsA7al",
        "colab_type": "text"
      },
      "source": [
        "## SkipGram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlaayQYtBiy2",
        "colab_type": "code",
        "outputId": "218dff2f-d49e-4a81-d956-c7d39eeb7ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#!wget http://143.107.183.175:22980/download.php?file=embeddings/word2vec/skip_s300.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-16 22:05:29--  http://143.107.183.175:22980/download.php?file=embeddings/word2vec/skip_s300.zip\n",
            "Connecting to 143.107.183.175:22980... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 958619745 (914M) [application/octet-stream]\n",
            "Saving to: ‘download.php?file=embeddings%2Fword2vec%2Fskip_s300.zip’\n",
            "\n",
            "download.php?file=e 100%[===================>] 914.21M  5.58MB/s    in 2m 18s  \n",
            "\n",
            "2020-04-16 22:07:47 (6.64 MB/s) - ‘download.php?file=embeddings%2Fword2vec%2Fskip_s300.zip’ saved [958619745/958619745]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIOP7_dhDNis",
        "colab_type": "code",
        "outputId": "3870f086-464b-4507-c45e-721abf133d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip '/content/drive/My Drive/Colab Notebooks/word2vec/skip_s300.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Colab Notebooks/word2vec/skip_s300.zip\n",
            "  inflating: skip_s300.txt           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfKPLdtYEx6l",
        "colab_type": "code",
        "outputId": "98df6042-b764-4919-83eb-7ebc56de0e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "skipgran_300 = '/content/drive/My Drive/Colab Notebooks/word2vec/skip_s300.txt'\n",
        "model_skipgran = KeyedVectors.load_word2vec_format(skipgran_300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pp3EO5jGIqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "skipgran_matrix_train = create_vector_matrix( model_skipgran, 300, word_tokinizer,  to_vector, train_data_frame.title)\n",
        "skipgran_matrix_test = create_vector_matrix( model_skipgran, 300, word_tokinizer,  to_vector, test_data_frame.title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_jOLvxiHAgo",
        "colab_type": "code",
        "outputId": "6ab350a0-3730-4085-9bca-98f2e0638fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lr = LogisticRegression(max_iter=800)\n",
        "\n",
        "lr.fit(skipgran_matrix_train, train_data_frame.category)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=800,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc5w_vW0He9l",
        "colab_type": "code",
        "outputId": "1a69cd8a-69a7-4281-ebcb-c44333517e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr.score(skipgran_matrix_test, test_data_frame.category)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7094777777777778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pWB4ESyHnGe",
        "colab_type": "code",
        "outputId": "3a26d6ba-163b-47c4-cd7c-ff6fd23e589d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "label_predict = lr.predict(skipgran_matrix_test)\n",
        "cr = classification_report( test_data_frame.category, label_predict) \n",
        "print(cr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     colunas       0.50      0.79      0.61     15000\n",
            "   cotidiano       0.82      0.70      0.75     15000\n",
            "     esporte       0.80      0.91      0.85     15000\n",
            "   ilustrada       0.92      0.23      0.37     15000\n",
            "     mercado       0.68      0.84      0.75     15000\n",
            "       mundo       0.83      0.79      0.81     15000\n",
            "\n",
            "    accuracy                           0.71     90000\n",
            "   macro avg       0.76      0.71      0.69     90000\n",
            "weighted avg       0.76      0.71      0.69     90000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}